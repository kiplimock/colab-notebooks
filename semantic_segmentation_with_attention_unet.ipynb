{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQxhKFsF1kype8PfRCLahX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiplimock/colab-notebooks/blob/main/semantic_segmentation_with_attention_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Augemented U-Net for Tree Crown Segmentation\n",
        "\n",
        "Based on the following papers:\n",
        "\n",
        "1. Jodas, D. S., Velasco, G. D. N., de Lima, R. A., Machado, A. R., & Papa, J. P. (2023). Deep Learning Semantic Segmentation Models for Detecting the Tree Crown Foliage. In VISIGRAPP (4: VISAPP) (pp. 143-150). https://www.scitepress.org/PublishedPapers/2023/116046/116046.pdf\n",
        "\n",
        "2. Woo, S., Park, J., Lee, JY., Kweon, I.S. (2018). CBAM: Convolutional Block Attention Module. In: Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds) Computer Vision - ECCV 2018. ECCV 2018. Lecture Notes in Computer Science(), vol 11211. Springer, Cham. https://doi.org/10.1007/978-3-030-01234-2_1"
      ],
      "metadata": {
        "id": "wA-RpUrmavVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://camo.githubusercontent.com/c40a3febddbb349098cf67e237a46f09489a098907772edc30619877f2980039/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d31307532665a6c2d4f4761364a45435f433852493038576933484356574f727057\" alt=\"model architecture\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "kbyn5iMycJTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CBAM Module Architecture\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.springernature.com/full/springer-static/image/chp%3A10.1007%2F978-3-030-01234-2_1/MediaObjects/474212_1_En_1_Fig1_HTML.gif?as=webp\" alt=\"cbam architecture\">\n",
        "</p>\n",
        "\n",
        "### Submodules of CBAM\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.springernature.com/full/springer-static/image/chp%3A10.1007%2F978-3-030-01234-2_1/MediaObjects/474212_1_En_1_Fig2_HTML.gif?as=webp\" alt=\"cbam submodules\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "Higb0t6WdVgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "m-nyfcFOc892"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Input\n",
        "from tensorflow.keras.layers import Activation, Concatenate, Conv2D, Multiply"
      ],
      "metadata": {
        "id": "D2aD5UG9c_Eu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Module"
      ],
      "metadata": {
        "id": "iM_AAMiBOUnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementation of CBAM: Convolutional Block Attention Module in the TensorFlow 2.5.\n",
        "Paper: https://arxiv.org/pdf/1807.06521\n",
        "Code: https://github.com/nikhilroxtomar/Attention-Mechanism-Implementation/blob/main/TensorFlow/cbam.py\n",
        "\"\"\"\n",
        "\n",
        "def channel_attention_module(x, ratio=8):\n",
        "    batch, _, _, channel = x.shape\n",
        "\n",
        "    ## Shared layers\n",
        "    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n",
        "    l2 = Dense(channel, use_bias=False)\n",
        "\n",
        "    ## Global Average Pooling\n",
        "    x1 = GlobalAveragePooling2D()(x)\n",
        "    x1 = l1(x1)\n",
        "    x1 = l2(x1)\n",
        "\n",
        "    ## Global Max Pooling\n",
        "    x2 = GlobalMaxPooling2D()(x)\n",
        "    x2 = l1(x2)\n",
        "    x2 = l2(x2)\n",
        "\n",
        "    ## Add both the features and pass through sigmoid\n",
        "    feats = x1 + x2\n",
        "    feats = Activation(\"sigmoid\")(feats)\n",
        "    feats = Multiply()([x, feats])\n",
        "\n",
        "    return feats\n",
        "\n",
        "def spatial_attention_module(x):\n",
        "    ## Average Pooling\n",
        "    x1 = tf.reduce_mean(x, axis=-1)\n",
        "    x1 = tf.expand_dims(x1, axis=-1)\n",
        "\n",
        "    ## Max Pooling\n",
        "    x2 = tf.reduce_max(x, axis=-1)\n",
        "    x2 = tf.expand_dims(x2, axis=-1)\n",
        "\n",
        "    ## Concatenat both the features\n",
        "    feats = Concatenate()([x1, x2])\n",
        "    ## Conv layer\n",
        "    feats = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(feats)\n",
        "    feats = Multiply()([x, feats])\n",
        "\n",
        "    return feats\n",
        "\n",
        "def cbam(x):\n",
        "    x = channel_attention_module(x)\n",
        "    x = spatial_attention_module(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "3AP3TMZhOVtJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depthwise Block"
      ],
      "metadata": {
        "id": "ffCssMt8vVzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def depthwise_block(input, num_filters):\n",
        "  d1 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same', depthwise_initializer='he_normal')(input)\n",
        "  d1 = tf.keras.layers.Conv2D(num_filters, (1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal')(d1)\n",
        "  d1 = cbam(d1)\n",
        "  d1 = tf.keras.layers.BatchNormalization()(d1)\n",
        "  d1 = tf.keras.layers.Activation('relu')(d1)\n",
        "\n",
        "  return d1"
      ],
      "metadata": {
        "id": "fQL163UMvYss"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv2D Block"
      ],
      "metadata": {
        "id": "LmCePTdNkfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_block(input, num_filters):\n",
        "  d1 = depthwise_block(input, num_filters)\n",
        "  d2 = depthwise_block(d1, num_filters)\n",
        "\n",
        "  shortcut = tf.keras.layers.Conv2D(num_filters, (1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal')(input)\n",
        "  shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "\n",
        "  out = tf.keras.layers.add([shortcut, d2])\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "QbdcHIz5kefF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(128, 128, 3))\n",
        "conv2d_block(inputs, 64).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6843i7-fWhU",
        "outputId": "9cc73111-b65c-4c08-8fd4-bfca7b69881b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 128, 128, 64)\n",
            "(None, 128, 128, 64)\n",
            "(None, 128, 128, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 128, 128, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contraction Path"
      ],
      "metadata": {
        "id": "BxaaEvlCPCWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "IMG_CHANNELS = 3"
      ],
      "metadata": {
        "id": "bTgnKlHUQN9i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Building the model\n",
        "input = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "input = tf.keras.layers.Lambda(lambda x: x / 255.0)(input)"
      ],
      "metadata": {
        "id": "xtEwdTIRP4DA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contraction path\n",
        "c1 = conv2d_block(input, 64)\n",
        "p1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c1)\n",
        "\n",
        "c2 = conv2d_block(p1, 128)\n",
        "p2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c2)\n",
        "\n",
        "c3 = conv2d_block(p2, 256)\n",
        "p3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c3)\n",
        "\n",
        "c4 = conv2d_block(p3, 512)\n",
        "p4 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "b5 = conv2d_block(p4, 1024)\n",
        "d5 = tf.keras.layers.Dropout(0.3)(b5)"
      ],
      "metadata": {
        "id": "K-7yPa6gQmqD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://camo.githubusercontent.com/c40a3febddbb349098cf67e237a46f09489a098907772edc30619877f2980039/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d31307532665a6c2d4f4761364a45435f433852493038576933484356574f727057\" alt=\"model architecture\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "fJ0sRFgBT7Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# expansion path\n",
        "u6 = tf.keras.layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(b5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "# u6 shape = (None, 28, 28, 1024)\n",
        "\n",
        "u7 = depthwise_block(u6, 512)\n",
        "u7 = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(u7)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "# u7 shape = (None, 56, 56, 512)\n",
        "\n",
        "u8 = depthwise_block(u7, 256)\n",
        "u8 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(u8)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "# u7 shape = (None, 112, 112, 256)\n",
        "\n",
        "u9 = depthwise_block(u8, 128)\n",
        "u9 = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(u9)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1])\n",
        "# u9 shape = (None, 224, 224, 128)\n",
        "\n",
        "u10 = depthwise_block(u9, 64)\n",
        "u10 = tf.keras.layers.Conv2D(1, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal')(u10)\n",
        "print(u10.shape)"
      ],
      "metadata": {
        "id": "EAQd1TkoSJf3",
        "outputId": "85e22cd2-56a4-40c1-bedb-6bfbed312282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 1)\n"
          ]
        }
      ]
    }
  ]
}